\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{pdfpages}
\usepackage{listings}
\usepackage{color}
\usepackage{lmodern}
\usepackage{hyperref}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\pagestyle{headings}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\textheight}{9in}
\setlength{\textwidth}{6.5in}
\setlength{\topmargin}{-0.5in}
\setlength{\headheight}{14pt}
\renewcommand*\rmdefault{lmss}
\renewcommand*\contentsname{Table of Contents}
\lstset{language=Matlab,
	aboveskip=3mm,
	belowskip=3mm,
	showstringspaces=false,
	basicstyle={\normalfont\ttfamily},
	numbers=left,
	numberstyle=\tiny\color{gray},
	keywordstyle=\color{blue},
	commentstyle=\color{dkgreen},
	stringstyle=\color{mauve},
	breaklines=true,
	breakatwhitespace=true,
	tabsize=4
}

\newcommand{\horizontalLine}{
	\begin{center}
		\hrule width 1.0\textwidth
	\end{center}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{\vspace{-3ex}\bf Final Project Report\\[2ex] 
       \normalsize ECS 171: Machine Learning\\Fall 2015}
\date{\today}
\author{\bf Team Name: The Muses\\ \bf William Otwell ()\\ \bf Marshall Hampson ()\\ \bf Nicholas Layton (996933702)\\ \bf Steven Mackey ()\\ \bf Amos Too ()\\ \bf Michael Fiueroa ()\\ \bf Peggy Li ()}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\maketitle
\pagebreak
\tableofcontents
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Abstract}
\label{sec:abstract}
One-two sentences on what is the problem that you addressing. Two-three sentences
that contain a high-level description on how you address the problem (your method). 2-3 sentences
on the results. 1 sentence on what the advance that has been achieved with this work
can influence the field (what it will enable, for the specific field and whole area in general)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\horizontalLine
\section{Introduction}
\label{sec:introduction}
1-2 sentences of the general area, 1-2 sentences on the specific sub-area. A paragraph
on the specific problem and how it has been addressed so far. 1-2 sentences to a paragraph
on what is missing on current approaches and why this is important.
Then a paragraph on what this paper contributes - how you approach this problem and the
results of the approach - This paragraph should have \textbf{\textit{clear}}, \textbf{\textit{definite}} \textbf{\textit{claims}} on what you have
achieved in relation to what you claimed that is missing in the field (from the previous paragraph).
You should not add items that do not relate to the previous "missing/desired" advances
that you introduced before. If this happens, then either you have not introduced the challenges/missing/desired
in the previous paragraph adequately, or your claim is irrelevant to this
paper and has to be removed.
Some people include a last paragraph with the structure of the paper as the closing introduction
paragraph. This is up to you.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\horizontalLine
\section{Methods}
\label{sec:methods}


 Divide it into sections that are well-defined on the distinct components/algorithms/subproblems.
 Put references whenever you use/step on previously published work. Use sub-section
 indexing (3.1, 3.2, etc.). Describe fully your algorithms and methods, so that if anyone wants to
 reproduce your results can do so (sometimes this is difficult if there are many parameters, in
 which case a parameter file should be included as suppl. mat.).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Linear Regression: Predicting Song Popularity}
\label{subsec:linearRegression}
blah blah blah

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Artificial Neural Networks}
\label{subsec:ann}
We utilized Neural Networks to predict song genres based on features of a song. Being that a song could be considered a part of multiple genres, each song contained a list of genres to which it belonged. To represent the genres, also known as tags, for a particular song, we formed a feature column for each possible tag in our dataset. Then, we scanned through each song to determine its set of tags and set the index of each tag to a 1 in the appropriate column if the tag was present for the particular song. 

We quickly found that if we included all of the possible tags that the number of tags would reach an unmanageable amount. It became too complex and computationally intensive to continue with such a large number of tags. Instead, we decided to limit the number of tags to a small subset of the most popular tags. Luckily, our dataset came with a list of the 300 most popular genres in the dataset. We were able to import this list and use it as the limiting set of possible tags for our dataset. Ultimately, we resorted to limiting the possible number of tags to only the top 20 genres, which resulted in an output layer of 20 nodes.

The features that we decided to use for predicting the song tags were: 
\begin{itemize}
    \item danceability
    \vspace{-3.5mm}
    \item duration
    \vspace{-3.5mm}
    \item end of fade in
    \vspace{-3.5mm}
    \item energy
    \vspace{-3.5mm}
    \item key
    \vspace{-3.5mm}
    \item loudness
    \vspace{-3.5mm}
    \item mode
    \vspace{-3.5mm}
    \item song hotness
    \vspace{-3.5mm}
    \item start of fade out
    \vspace{-3.5mm} 
    \item tempo
    \vspace{-3.5mm}
    \item time signature
    \vspace{-3.5mm}
    \item year
\end{itemize}

We were interested in observing the effect of 3 different parameters on the neural network: learning rate, number of hidden layers, and number of hidden nodes per hidden layer. We planned on running our dataset through various neural networks, each with a different configuration of the above parameters. We hoped to find an optimal configuration for these parameters while also discovering any correlation between the above song features and the song tags. A particular configuration of these parameters that yielded both minimal training error and misclassification rate would implicitly verify a correlation between song features and song tags.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Clustering}
\label{subsec:kMeans}
We took two different approaches to clustering our data: k-means and hierarchical. We looked at k-means to try and see if there had any obvious patterns and then see if those patterns held any significance for genre or song hotness. Hierarchical gave us insight to the distribution of our data and helped us select the appropriate number of clusters for k-means. For both approaches we chose to use MATLAB and take advantage of the built-in clustering methods.
\\ \\
Initially we chose to look at the following features:
\begin{itemize}
\item danceability
\vspace{-3.5mm}
\item duration
\vspace{-3.5mm}
\item end of fade in
\vspace{-3.5mm}
\item energy
\vspace{-3.5mm}
\item key
\vspace{-3.5mm}
\item loudness
\vspace{-3.5mm}
\item mode
\vspace{-3.5mm}
\item song hotness
\vspace{-3.5mm}
\item start of fade out
\vspace{-3.5mm} 
\item tempo
\vspace{-3.5mm}
\item time signature
\vspace{-3.5mm}
\item year
\end{itemize}

We ran these through the MATLAB k-means function and viewed the clusters of all these features plotted against song hotness. We heard that the general rule of thumb was to run k-means on the sqrt(n/2) clusters. However we found that this did not produce distinct clusters and was very muddy. We found four clusters were the most distinct visually, but we did not check if it maximized the variance.

We found that the clusters seemed to be skewed by issues with our data set. We noticed that danceability and energy where all 0 in the provided dataset (the value was supposed to range between 0 and 1). Therefore we decided to throw out those two columns. We also threw out year and mode because the ended up being nearly categorical in that their normalized values were almost 0 or almost 1. Another issue we noticed is that some of the song hotness values where either 0 or NaN so we removed datapoints where this was the case. After removing these features and datapoints from the dataset we found we got better clusters.

To get the hierarchical clusters and plot the dendrogram we used the MATLAB functions dendrogram and linkage. The linkage function returns a tree of when to clusters are linked together. We decided to view the dendrogram with at most 50 distinct clusters. We found that there were really 4 distinct leaves. After the 4 initial splits the splits didn't look any more significant than when we plotted a dendrogram for random data. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\horizontalLine
\section{Results}
\label{sec:results}

This should only describe the results that you have obtained. Sometimes it make sense
to discuss your guess/opinion why this is happening, but this should be rare. This section is to
only present the facts about the method performance, robustness, complexity, etc.

This is where you discuss everything that was presented in the Results section.
Why did the algorithm perform better in X and not in Y. It is ok to succinctly re-state strong
result claims (that were included in the previous section), as long as you continue to explain,
even speculate why this may be the case. For example: "Our algorithm was faster in X\% of the
scenarios than what is currently available. The main drive behind this performance boost is the
Y module, which takes advantage of the Z characteristic of the problem. Indeed, ...."

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Linear Regression: Predicting Song Popularity}
\label{subsec:linearRegressionResults}
blah blah blah

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Artificial Neural Networks}
\label{subsec:annResults}
blah blah blah

\subsubsection{The Effect of Learning Rate on Training}
\label{subsubsec:annLearningRateResults}
blah blah blah

\subsubsection{The Effect of Hidden Layers on Training and Accuracy}
\label{subsubsec:annHiddenLayerResults}
blah blah blah

\subsubsection{The Effect of Hidden Layer Nodes on Training and Accuracy}
\label{subsubsec:annHiddenLayerNodesResults}
blah blah blah

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Clustering}
\label{subsec:kMeansResults}
blah blah blah

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\horizontalLine
\section{Conclusion}
\label{sec:conclusion}
Finally, in what some papers refer to as "Conclusion", you provide 1-2 sentences of the purpose
of this report and 1-2 sentences of what was achieved (these 2-4 sentences are usually similar
or re-stating what was said in the abstract). Then you go on to discuss about what remains to
be done (the road ahead), why (the impact to the field) and how you think it can be achieved
(future work). You end the report with 1-2 sentences on how the work presented advances the
field in the grant scheme of things.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\horizontalLine
\section{References}
\label{sec:references}
 Please include all relevant references for the paper, to provide a succinct and accurate
 summary of past work and challenges in the field. Research has found that the more
 2
 articles you cite, the more you will be cited too. For this report you are expected to have 10-20
 references.
\\ \\
\href{http://courses.cs.washington.edu/courses/csep521/07wi/prj/michael.pdf}{Pandora's Music Recommender} - Michael Howe 

Michael Howe's paper describes likely methods and means involved with Pandora's classification and recommendation system. It covers elements of the Music Genome Project and the ways Pandora applies machine learning to both suggesting new music to users and building music taxonomy. By using over 400 features that break down music into its basic elements, Pandora is able to create useful taxonomy that is applied when suggesting music to users. During the act of recommending music, Howe suggests that it is likely that Pandora clusters users and uses that as a factor in determining songs to offer the user. By building neighborhoods of users through clustering, Pandora is successfully attracting loyal users.
\\ \\
\href{http://www.google.com/patents/US7003515?dq=7,003,515}{Music Genome Project Patent} - William T. Glaser 

The patent describes  ``A method of determining at least one match item corresponding to a source item'' and a database that is created to facilitate such functionality. It involves calculating two distances between a source song vector and  first and second database song vectors. The result is then used to select a song match that is based on the magnitudes of these distances.
\\ \\
\href{http://www.medwelljournals.com/fulltext/?doi=ijscomp.2009.168.172}{Impact of Normalization in Distributed K-Means Clustering} - N. Karthikeyani Visalakshi 

The paper illustrates why normalizing data and using that in conjunction with K-means is essentially good method of aiding clustering. After several ``Comprehensive experiments on six benchmark numerical datasets'' the authors also concluded that selecting a specific method of normalization that fits the dataset is essential for this approach to work.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\horizontalLine
\section{Author Contributions}
\label{sec:authorContributions}

\begin{itemize}
    \item Methods:
    \begin{itemize}
        \item Linear Regression
        \begin{itemize}
            \item Peggy Li:
            \item Steven Mackey:
        \end{itemize}
        \item Artificial Neural Network
        \begin{itemize}
            \item Nicholas Layton:
            \item Michael Fiueroa:
        \end{itemize}
        \item K-Means Clustering
        \begin{itemize}
            \item William Otwell:
            \item Marshall Hampson:
            \item Amos Too:
        \end{itemize}
    \end{itemize}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\horizontalLine
\appendix
\section{Figures}
\label{sec:figures}

\end{document}

